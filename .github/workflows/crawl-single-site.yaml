---
name: single url crawl

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'url to test'
        required: true
        default: 'https://www.sonarqube.ucl.ac.uk'
        type: string
      depth:
        description: 'depth of website to crawl'
        required: true
        default: 2
        type: int
      notify_email:
        description: 'notify email'
        required: false
        default: ''
        type: string

env:
  E_FDOMAINS:
  E_TDOMAINS:
  E_COOKIES:
  E_LISTNERS:
  E_TRACKERS:

run-name: "single url crawl ${{ inputs.url }} depth: ${{ inputs.depth }}"

jobs:
  crawl_site:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-go@v6
        with:
          go-version: '1.20'
      - run: |
          go version
          GO111MODULE=on go install github.com/jaeles-project/gospider@latest
          $HOME/go/bin/gospider --help
      - name: crawl and report
        env:
          URL: ${{ inputs.url }}
          DEPTH: ${{ inputs.depth }}
        run: |
          time $HOME/go/bin/gospider -d ${DEPTH} -c 10 -s ${URL} | tr -d '\r' > crawl1.out
          grep -v -E '\[(form|subdomains|linkfinder|javascript)\]' crawl1.out |\
           grep -v -E 's/(.js|.css|.jpg|favicon.ico|.svg|.pdf)$//g' |\
           grep -v -E 's/(.js|.css)?ver=//g' |\
           sed -e 's/^.* - //g' -e 's/http:/https:/g' -e 's/\/$//g' |\
           grep -v '\[code-40?\]' | grep -v '^mailto:' | grep "^${URL}" |\
           grep -v wp-json/oembed |\
           sort -u > gospider.out

          export ENTRIES=$(wc -l gospider.out | cut -d ' ' -f1)
          echo "# entries: ${ENTRIES}"
          set -x
          echo "l(${ENTRIES})/l(10)" | bc -l 
          BIG_O=$(echo "l(${ENTRIES})/l(10)" | bc -l | sed 's/\.*$//g')
          echo $BIG_O
          echo "### URL: [${URL}] crawl depth: [${DEPTH}]" >> $GITHUB_STEP_SUMMARY
          echo "### Crawled page count: [${ENTRIES}]" >> $GITHUB_STEP_SUMMARY
          echo "### Big O: [${BIG_O}]" >> $GITHUB_STEP_SUMMARY


