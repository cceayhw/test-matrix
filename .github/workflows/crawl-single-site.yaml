---
name: crawl single url

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'url to test'
        required: true
        default: 'https://www.sonarqube.ucl.ac.uk'
        type: string
      depth:
        description: 'depth of website to crawl'
        required: true
        default: 10
        type: int
      notify_email:
        description: 'notify email'
        required: false
        default: ''
        type: string

env:
  E_FDOMAINS:
  E_TDOMAINS:
  E_COOKIES:
  E_LISTNERS:
  E_TRACKERS:

run-name: "single url crawl ${{ inputs.url }} depth: ${{ inputs.depth }}"

jobs:
  crawl_site:
    runs-on: ubuntu-latest
    outputs:
      NUM_ENTRIES: ${{ steps.crawl.outputs.entries }}
      BIG_O: ${{ steps.crawl.outputs.big_o }}
      SITE_SIZE: ${{ steps.crawl.outputs.size }}
      MATRIX_N: ${{ steps.crawl.outputs.matrix_n }}
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-go@v6
        with:
          go-version: '1.20'
      - run: |
          go version
          GO111MODULE=on go install github.com/jaeles-project/gospider@latest
          $HOME/go/bin/gospider --help
      - name: crawl_n_report
        id: crawl
        env:
          URL: ${{ inputs.url }}
          DEPTH: ${{ inputs.depth }}
        run: |
          ./crawl.sh ${URL} ${DEPTH}
      - name: create artifact
        uses: actions/upload-artifact@v4
        with:
          name: crawl_output
          path: gospider.out
          if-no-files-found: warn
          retention-days: 1
  matrix-checks:
    runs-on: ubuntu-latest
    needs: crawl_site
    strategy:
      matrix:
        node_n: ${{ fromJson(needs.crawl_site.outputs.MATRIX_N) }}
      fail-fast: false
      max-parallel: 10
    steps:
      - uses: actions/checkout@v5
      - uses: actions/checkout@v5
        with:
          repository: 'the-markup/blacklight-query'
          path: blacklight-query
      - name: get crawled page list
        uses: actions/download-artifact@v4
        with:
          path: .
      - uses: actions/setup-node@v4
        with:
          node-version: '20.15.1'
      - name: node
        working-directory: ./blacklight-query
        run: npm install
      - name: run thread ${{ matrix.node_n }}
        working-directory: ./blacklight-query
        env:
          NODE_N: ${{ matrix.node_n }}
        run: |
          ../query.sh ${NODE_N} ../crawl_output/gospider.out
      - name: create artifact
        uses: actions/upload-artifact@v4
        with:
          name: blacklight-report-${{ matrix.node_n }}
          path: blacklight-query/outputs/**
          if-no-files-found: warn
          retention-days: 1
  merge-artifacts:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    needs: matrix-checks
    if: success() || failure()
    steps:
      - uses: actions/checkout@v5
      - name: get artifacts
        uses: actions/download-artifact@v4
        with:
          path: reports
      - name: generate report
        run: |
          ./summary.sh ${GITHUB_RUN_ID} crawl_summary_${GITHUB_RUN_ID}.md
          ls -lR
      - name: upload merged
        uses: actions/upload-artifact@v4
        with:
          name: merged-reports
          path: |
            reports/**
            data/a.in
            crawl_summary*.*
          if-no-files-found: warn
          retention-days: 1
      - name: delete matrix artifacts
        uses: geekyeggo/delete-artifact@v5
        with:
          name: |
            blacklight-report-*
            crawl_output